\documentclass[12pt]{article}

\usepackage[a4paper, total={185mm, 265mm}]{geometry} %A4: 210px * 297px

\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[ngerman]{babel}
\usepackage[T1]{fontenc} % Output font encoding for international characters

%\usepackage{slickstempaper}
\input{slick_stem_paper_input}

\addbibresource{literature.bib} % The filename of the bibliography

\begin{document}
\centerline{\sc \Huge Tensor}
\centerline{\sc \normalsize Dokumentation für das Tensor Crate}
\vspace{.5pc}
%\begin{center}
%\includegraphics[width=1.0\textwidth]{images/logo.png}
%\end{center}
\vspace{.5pc}
\centerline{\sc \large von Nextdorf}
\vspace{1.5pc}

\tableofcontents

\section{Mathematische Definition}
\subsection{Vektorraum}
\subsubsection{Allgemein}
Ein Vektorraum $(V, \mathbb K, \cdot)$ besteht aus einer abelschen Gruppe $V$, einem Körper $\mathbb K$ und einer Abbildung $\cdot\colon \mathbb K \times V \to V$. Für $\alpha,\; \beta \in \mathbb K$ und $x,\; y \in V$ gilt:
\begin{flalign}
\bulletspace
\bullet \ & (\alpha + \beta) \cdot x = (\alpha\cdot x) + (\beta \cdot x) &&\\
\bullet \ & \alpha \cdot (x + y) = (\alpha\cdot x) + (\alpha \cdot y) &&\\
\bullet \ & (\alpha \beta) \cdot x = \alpha \cdot (\beta \cdot x) &&\\
\bullet \ & 1 \cdot x = x &&
\end{flalign}
Oftmals wird auch abkürzend die Bezeichnung für die Gruppe bzw. für die Menge und für den Vektorraum synonym verwendet. Auch ist die zusätzliche Definition $\cdot\colon V\times\mathbb K \to V,\; (x, \alpha) \mapsto \alpha \cdot x$ üblich und oftmals wird das Symbol für die Skalar-Multiplikation komplett weggelassen.

\subsubsection{Norm}
Auf dem Vektorraum $(V, \mathbb K, \cdot)$ bezeichnet die Abbildung $\norm{\cdot}\colon V \to \mathbb R$ eine Norm, falls für $\alpha \in \mathbb K$ und $x,\; y \in V$ gilt:
\begin{flalign}
\bulletspace
\bullet \ & \norm{x} = 0 \Rightarrow x = 0 &&\\
\bullet \ & \norm{\alpha x} = |\alpha|\;\norm{x} &&\\
\bullet \ & \norm{x+y} \leq \norm{x} + \norm{y} &&
\end{flalign}
Zusammen mit der Norm wird der Vektorraum auch als normierter Raum bezeichnet.

\subsubsection{Vollständiger Raum}
Es sei $(V, \norm{\cdot})$ ein normierter Raum und $( x_k )_{k\in \mathbb N} \subset V$ eine Folge. Die Folge ist eine Cauchy-Folge, falls sie das folgende Kriterium erfüllt:
\begin{align}
\forall \epsilon > 0\; \exists n \in \mathbb N\; \forall k, m \geq n\colon \norm{x_k - x_m} < \epsilon
\end{align}
Anschaulich ist eine Cauchy-Folge eine Folge, die im Unendlichen asymptotisch Konstant wird. Falls alle Cauchy-Folgen konvergieren, also wenn all diese asymptotischen Konstanten in $V$ enthalten sind, dann wird $V$ auch als vollständiger Raum bezeichnet.\\
Unvollständige Räume sind also Räume mit "Löchern". Allerdings kann man sie immer vervollständigen. Dazu betrachtet man die Menge aller Cauchy-Folgen und fasst die Folgen zusammen, die sich um eine Null-Folge unterscheiden:
\begin{align}
W =& \big\{ x \in C_V\colon \big\{ y \in C_V \big| \lim\limits_{k\to\infty} \norm{x_k - y_k} = 0 \big\} \big\} \\
&\text{wobei } C_V = \big\{x \in (V)_{\mathbb N} \big| \text{$x$ ist Cauchy-Folge} \big\} \nonumber
\end{align}
Durch verallgemeinern von $(+)_V$, $(\cdot)_V$ und $\norm{\cdot}_V$ auf $C_V$ wird $W$ zum vollständigen, normierten Raum. Im letzten Schritt identifiziert man die Elemente von $W$ mit ihren Grenzwerten, das heißt für $v \in V$ definiert man $x = (v_k)_{k\in \mathbb N} \in C_V$ und findet $w \in W$ mit $x \in w$ und man identifiziert $v$ mit $w$. Das wohl bekannteste Beispiel für die Vervollständigung eines Raumes ist die Definition von $\mathbb R$ als die Vervollständigung des Körpers $\mathbb Q$.

\subsubsection{Skalarprodukt}
Auf dem Vektorraum $(V, \mathbb K, \cdot)$ mit $\mathbb R \subset \mathbb K$ bezeichnet die bilineare Abbildung $\braket{\cdot}{\cdot}\colon V\times V \to K$ ein Skalarprodukt, falls für $\alpha \in \mathbb K$ und $x,\; y,\; z \in V$ gilt:
\begin{flalign}
\bulletspace
\bullet \ & \braket{x}{x} \geq 0 &&\\
\bullet \ & \braket{x}{x} = 0 \Leftrightarrow x = 0 &&\\
\bullet \ & \braket{x}{y} = \braket{y}{x}^*\; \text{mit } 0^* = 0,\; z^* = |z|^2/z &&\\
\bullet \ & \braket{x}{\alpha y + z} = \alpha \braket{x}{y} + \braket{x}{z} &&
\end{flalign}
Zusammen mit dem Skalarprodukt wird der Vektorraum auch als Skalarproduktraum oder Prähilbertraum bezeichnet.\\
Insbesondere induziert das Skalarprodukt die Norm $x \mapsto \sqrt{\braket{x}{x}}$.

\subsubsection{Hilbertraum}
Ein Hilbertraum ist ein Skalarproduktraum für den die induzierte Norm einen vollständigen Raum ergibt.


\subsection{Dualraum}
\subsubsection*{Allgemein}
Für den Vektorraum $V \equiv (V, \mathbb K, \cdot)$ lässt sich die Menge der linearen Abbildungen $L(V \to \mathbb K)$ definieren. Wir definieren:
\begin{flalign}
\bulletspace
\bullet \ & +\colon L(V \to \mathbb K) \times L(V \to \mathbb K) \to L(V \to \mathbb K),\; (f,g) \mapsto \big( x \mapsto f(x) + g(x) \big) \label{dual add}&&\\
\bullet \ & \cdot\colon \mathbb K \times L(V \to \mathbb K) \to L(V \to \mathbb K),\; (\alpha, f) \mapsto \big( x \mapsto \alpha f(x) \big) \label{dual mul} &&
\end{flalign}
Somit bilden $(L(V \to \mathbb K), +)$ eine abelsche Gruppe und $((L(V \to \mathbb K), +), \mathbb K, \cdot)$ ein Vektorraum. Dieser induzierte Vektorraum heißt auch Dualraum von $V$ und wird mit $V^\dagger$ bezeichnet.

\subsubsection*{Norm}
Ist $V$ zudem normiert, dann lässt sich außerdem noch eine Norm auf $V^\dagger$ induzieren:
\begin{align}
\norm{\cdot} \colon V^\dagger \to \mathbb K,\; f \mapsto \sup_{\norm{x} = 1} |f(x)|
\end{align}
In dem Fall bezeichnet der Dualraum üblicherweise nur die Elemente mit endlicher Norm, also
\begin{align*}
V^\dagger = \big\{f \in L(V \to \mathbb K) \;\big| \sup\limits_{\norm{x} = 1} |f(x)| < \infty \big\}
\end{align*}
Es gibt noch weitere Normen, die Induziert werden, aber solange nicht anders angegeben, gehen wir hier von dieser Standardnorm für den Dualraum aus.

\subsubsection*{Zusammenhang zum Skalarprodukt und Hilberträumen}
Oftmals ist es im Zusammenhang zum Skalarprodukt interessant die linearen Abbildungen $l_x\colon y \mapsto \braket{x}{y}$ für $x$ beliebig aber fest zu betrachten. Es gilt nämlich $\norm{l_x} = \norm{x} < \infty$ und somit auch $l_x \in V^\dagger$. Insbesondere besagt der Darstellungssatz von Fréchet-Riesz für Hilberträume, dass
\begin{align}
V^\dagger = \big\{ x \in V\colon l_x \big\}
\end{align}
In der Braket-Notation verdeutlicht man den Zusammenhang damit, dass Kets $\ket x$ Vektorraumelemente darstellen und Bras $\bra x$ entsprechend Dualraumelemente darstellen.

\subsection{Tensoren}
Ein Tensor ist im Grunde die Idee von Skalarprodukträumen und induzierten Dualräumen verallgemeinert auf beliebige multilineare Objekte. Wir definieren:
\begin{align}
V^{(0, 0)} \coloneqq \mathbb K,\;  V^{(r+1, s)} \coloneqq \bigoplus_{v\in V} V^{(r, s)} \times v,\; V^{(r, s+1)} \coloneqq \bigoplus_{v\in V^\dagger} V^{(r, s)} \times v
\end{align}
Insbesondere entspricht $V^{(1, 0)} \equiv V$ und $V^{(0, 1)} \equiv V^\dagger$. Der gesamte Tensorraum $T_V$ ist dann definiert als
\begin{align}
T_V = \bigoplus_{r,s = 0}^\infty V^{(r, s)}
\end{align}
Es seien $t\equiv \sumint_k (x^1_k, x^2_k, \dots), u\equiv \sumint_k (y^1_k, y^2_k, \dots) \in T_V$, wobei $x^i_\cdot \in T^\dagger$ und $y^j_\cdot \in T$, dann definiere die Kontraktion als multilineare Abbildung:
\begin{align}
&C_i^j(t, u) \coloneqq \sumint_{k, l} x^i_k(y^j_l) \cdot \big(x^1_k, \dots, x^{i-1}_k, x^{i+1}_k, \dots, y^1_l, \dots, y^{j-1}_l, y^{j+1}_l, \dots\big)\\
&t \in V^{(a, b)},\; u \in V^{(a', b')} \Rightarrow C_i^j(t, u) \in V^{(a+a'-1, b+b'-1)}
\end{align}
Da jeder Vektorraum eine Basis hat, können wir eine Basis $(\vec e_i)_{i\in I}$ für $V$ betrachten. Entsprechend bildet auf Hilberträumen $(\vec e^i)_{i\in I}$ eine Basis für $V^\dagger$ wobei $\vec e^i(\vec e_j) \coloneqq \delta^i_j$.\\
Um die Notation in der Rechnung zu vereinfachen (handlich, falls der Rang relativ niedrig ist), schreibt man den Tensor oft in Index-Schreibweise. Ist also $t \in V^{k_1} \times V^{\dagger\; l_1} \times V^{k_2} \times V^{\dagger\; l_2} \times \dots$, dann ist
\begin{align}
t = \sumint_{a_1,\dots a_{k_1}, b_1,\dots, b_{l_1}, \dots \in I} \; t\indices{^{a_1\cdots a_{k_1}} _{b_1\cdots b_{l_1}} ^{c_1\cdots c_{k_2}} _{d_1\cdots d_{l_2}}} \phantom{0} \indices*{^\cdots_\cdots} \; \big( \vec e_{a_1}, \dots, \vec e_{a_{k_1}}, \vec e^{b_1}, \dots, \vec e^{b_{l_1}}, \dots \big)
\end{align}
Tensoren werden bei fester Basis dann mit $t\indices*{^\cdots_\cdots}$ notiert. Anhand der Stellung des Index im Tensor kann man ablesen, ob er mit der Vektorbasis kontrahiert wird (diese stehen oben und heißen \textbf{kontravariante Indizes}), oder ob er mit der Dualbasis kontrahiert wird (diese stehen unten und heißen \textbf{kovariante Indizes}).\\
In der Einsteinschen Summenkonvention werden Summenzeichen ebenfalls weggelassen und gleichnamige Indizes werden kontrahiert. Hier einige Beispiele in den definierten Konventionen:
\begin{flalign*}
\bulletspace
\bullet \ & x \in V = V^{(1, 0)} \Rightarrow x = x^i \vec e_i &&\\
\bullet \ & f \in V^\dagger = L(V \to \mathbb K) = V^{(0, 1)} \Rightarrow f(x) = f_i x^i = f_i \vec e^i(x) = C^1_1(f, x) &&\\
\bullet \ & A \in L(V \to V) \subset V^{(1, 1)} \Rightarrow A(x) = A\indices{^i_j} \vec e_i x^j = A\indices{^i_j} \vec e_i \vec e^j(x) = C_2^1(A, x),\; (A(x))^i = A\indices{^i_j} x^j &&\\
\bullet \ & g \in L(V^2 \to \mathbb K) = V^{(0, 2)} \Rightarrow g(x, y) = g\indices{_i_j} x^i y^j = g\indices{_i_j} \vec e^i(x) \vec e^j(y) = C_1^1(C_1^1(g, x), y) = C_1^1(C_2^1(g, y), x) &&
\end{flalign*}
Unterschiedliche Basen notiert man anhand der Indizes. Beispielsweise würde man den Tensor $t$ in der Basis $B = (\vec e_k)_{k\in I}$ mit $t^k$ notieren und in $\bar B = (\vec e_{\bar k})_{\bar k \in \bar I}$ mit $t^{\bar k}$, sodass in der Einsteinschen Summenkonvention direkt klar ist, dass zwei Tensoren in unterschiedlicher Basis nicht ohne Basiswechsel kontrahiert werden können. Der Basiswechseloperator wäre entsprechend ein $V^{(1, 1)}$-Tensor mit kontravariantem Index in $B$ und kovariantem Index in $\bar B$. Üblicherweise nimmt man ein Symbol für den Tensor, der beim trivialem Basiswechsel zur Identität wird:
\begin{align}
\big( t_k \vec e^k \big) \big( u^{\bar l} \vec e_{\bar l} \big) = t_k \delta\indices{^k_{\bar l}} u^{\bar l} = t_k u^k\; \text{und } \delta\indices{^k_{\bar l}} = \vec e^k(\vec e_{\bar l})
\end{align}
Neben der Kontraktion zweier Tensoren will man oft auch zwei Indizes innerhalb des selben Tensores kontrahieren, bspw. entspräche $\tr(A) \equiv A\indices{^i_i}$. Man definiert für einen Tensor $t$ wobei der $i$-te Index kovariant und der $j$-te Index kontravariant ist:
\begin{align}
C_i^j(t) \coloneqq \begin{dcases}
\sumint_{k\in I} C_1^j(\vec e_k, C_i^1(t, \vec e^k)) \hspace{2pc}& i>j\\
\sumint_{k\in I} C_i^1(C_1^j(\vec e^k, t), \vec e_k) & i<j
\end{dcases}
\end{align}
Und für $A \in L(V \to V)$ ergibt sich insbesondere:
\begin{align*}
\tr(A) = C^1_2(A) = A\indices{^i_i}
\end{align*}

\section{Implementierung}
\subsection{Plannung}
Zur Konstruktion ist ein Vektorraum und ein Skalarprodukt nötig, sodass sich ein Hilbertraum ergibt. Der Vektorraum sollte ein Trait sein und den Körper über einen internen Type festlegen. Das Skalarprodukt kann über einen Trait "Prehilbertspace" definiert werden, welches den Vektorraum-Trait voraussetzt. Der Prähilbertraum auto-implementiert den normierten Raum, und dieser wiederum auto-implementiert einen Dualraum. "Hilbertspace" wäre dann einfach ein Marker-Trait, der den Trait Prehilbertspace voraussetzt. Es gibt ein \href{https://docs.rs/vector-space/latest/vector_space/index.html}{Crate}, das eigentlich genau das liefert, aber es geht von Copyable Daten aus. Man kann also kein "schweren" Vektoren darstellen. Mit dieser Einschränkung bin ich nicht all zu glücklich. Allerdings könnte ich meine Räume allgemeiner definieren und über Crate-Flags festlegen, dass dieses Trait miteingebunden wird und für auto-implemented wird.\\
Für die Tensoren wäre es vermutlich sinnvoll mit einer Basis-unabhängigen Implementierung zu beginnen. Dazu braucht es neben der Kontraktion zweier Vektoren noch die Möglichkeit Indizes zu tauschen und (zumindest auf Hilberträumen) die Möglichkeit Indizes zu heben und zu senken.

\subsection{Patterns für Supertraits und mathematischen Strukturen}
Das Ziel des Crates ist es die mathematischen Objekte in Rust's Typsystem darzustellen. Um eine Klasse von mathematischen Objekten, wie Zahlenkörper oder Vektorräume, darzustellen, müssen für diese Klassen Traits implementiert werden. Die Forderung nach der Existenz bestimmter Funktionen auf diesen Traits kann über Supertraits definiert werden. Für einen Trait \texttt T, der bspw. eine kommutative Gruppe darstellt, ist es sinnvoll, dass \texttt T einen Supertrait für die Addition implementieren muss. Allerdings stellt der Trait \lstinline[language=Rust, morekeywords={T}]|Add<T, Output = T>| ein Problem dar: \lstinline[language=Rust, morekeywords={T}]|_(T + &T) -> T|, \lstinline[language=Rust, morekeywords={T}]|_(&T + T) -> T| und \lstinline[language=Rust, morekeywords={T}]|_(&T + &T) -> T| könnten vermutlich effizienter implementiert werden. Insbesondere wenn es teuer ist \texttt T zu klonen oder zu konstruieren, kann das Ganze zu ungeahnt ineffizientem Code führen.\\
Betrachte als Beispiel ein Polynom vom Grad $n$. Auf algebraisch abgeschlossenen Körpern, wie den komplexen Zahlen zum Beispiel, kann man jedes Polynom $p$ immer vollständig zerlegen:
\begin{align*}
p(x) = p_0 \prod_{k=1}^N (x - x_k)^{r_k} \text{ mit } \sum_{k=1}^N r_k = n
\end{align*}
Wenn man die Potenz in Multiplikationen zerlegt, dann kann man $y^r$ in $\ceil{\log_2(r)}$ einzelne Schritte zerlegen. In Spezialfällen sind weitere Optimisierungen möglich, aber die wollen wir hier ausklammern. Es sei:
\begin{flalign*}
\bulletspace
\bullet\ & \Theta_{T+F} = \Theta(\lstinline[language=Rust]|<T as Add<Field, Output = T>>::add|) &&\\
\bullet\ & \Theta_{T\cdot F} = \Theta(\lstinline[language=Rust]|<T as Mul<Field, Output = T>>::mul|) &&\\
\bullet\ & \Theta_{T\cdot T} = \Theta(\lstinline[language=Rust]|<T as Mul<T, Output = T>>::mul|) &&
\end{flalign*}
Dann entspricht $x - x_k$ je einer Laufzeit von $\Theta_{T+F}$, $y^r$ entspricht $\ceil{\log_2(r)} \Theta_{T\cdot T}$, und $p_0 y_1 \cdot \dots \cdot y_N$ entspricht $(N-1) \Theta_{T\cdot T} + \Theta_{T\cdot F}$ und insgesamt:
\begin{align}
\Theta(p) = N\Theta_{T + F} + \big(N - 1 + \sum_{k=1}^N \ceil{\log_2(r_k)}\big) \Theta_{T\cdot T} + \Theta_{T\cdot F}
\end{align}
Würden wir allerdings die borrowed Parameter, anstatt owned Parameter wählen, dann müsste die Laufzeit $\Theta_{\text{new}}$ für das Klonen/Kopieren/Konstruieren mitberücksichtigt werden. Wir gehen davon aus, dass das Klonen in etwa genauso teuer ist wie das Konstruieren+Initialisieren anhand der referenzierten Werten. In der Praxis ist das wohl eher eine untere Schranke. Dann wäre:
\begin{align}
\Theta_* \to \Theta_* + \Theta_{\text{new}},\; \Theta(p) \to \Theta(p) + \big(2N + \sum_{k=1}^N \ceil{\log_2(r_k)}\big) \Theta_{\text{new}}
\end{align}
Einerseits will ich in meiner Library nicht einfach $\Theta_{\text{new}}$ für teure Typen vernachlässigen, wenn ich die Möglichkeit habe eine in-place Variante zu nutzen, andererseits will ich die Möglichkeit haben effizientere Varianten für out-of-place Varianten zu schreiben. Praktisch hieße das, dass ich für jeden dieser arithmetischen Supertraits alle 4 Kombinationen fordern müsste. Allerdings wird das Ganze sehr nervig, wenn man Constraints schreiben will und persönlich halte ich das für ein Code-Smell und Anti-Pattern.\\
Technisch sauberer wäre es den Supertrait zu ignorieren und die entsprechenden Methoden im Trait \texttt T zu definieren. Allerdings hat man dann nicht mehr den syntaktischen Zucker um \lstinline[language=Rust]|a + b| anstelle von \lstinline[language=Rust]|a.add(b)| schreiben zu können. Sauber aber unhandlich. Mir sind einige Möglichkeiten eingefallen das Problem mit Kompromissen zu lösen:
\begin{itemize}
\item \textbf{Copyable only}\\
Diese Lösung habe ich auf \href{https://crates.io}{crates.io} bei Crates mit ähnlichen Problemen am häufigsten angetroffen. Das nette am Copy-Trait ist nämlich, dass man eigentlich immer davon ausgehen kann, dass ein memcopy extrem billig ist. Außerdem ist er trivial, was insbesondere bedeutet, dass der Rust-Compiler sehr gut in der Lage ist potenzielle Optimierungen zu erkennen, sodass man \lstinline[language=Rust]|T: Add| bedenkenlos als einzige Implementierung für die Addition wählen kann. Außerdem sind copyable Typen in der Regel auch klein. Das heißt selbst der theoretische Overhead ist im Worst-Case kaum relevant. Das Problem mit dieser ``Lösung'' ist natürlich, dass viele interessanten Typen schlicht nicht copyable sind. Dazu zählt bspw. jeder Typ mit Heap-Allokationen.
\item \textbf{Constrained Newtype}\\
Hier benutzt man im Grunde die oben angesprochene, technisch saubere Variante und verbindet das Ganze mit einem dediziertem Newtype. Da der Newtype ein konkreter Datentyp ist, kann er alle Traits so implementieren wie man das Ganze für richtig hält. Es entsteht kein Overhead und man macht keine Einbusen in der Handlichkeit außer, dass man den eigentlichen Datentypen, der den Trait \texttt{GenGroup} implementiert wrappen und unwrappen muss. Das kann den Lese- und Schreibfluss unterbrechen, wenn man oft zwischen Funktionen auf \texttt{T} und Funktionen auf \texttt{GenGroup} bzw. \texttt{Group} wechseln muss. Aber das kann man mithilfe von \texttt{Into}, \texttt{AsRef}, \dots auf ein Minimum beschränken. Ein Beispiel für Gruppen:
\begin{lstlisting}[language=Rust, numbers=left]
// groups_example.rs
trait GenGroup {
	fn add(self, other: Self) -> Self;
	fn ref_add(&self, other: Self) -> Self;
	fn add_ref(self, other: &Self) -> Self;
	fn ref_add_ref(&self, other: &Self) -> Self;
	
	fn sub(self, other: Self) -> Self;
	fn ref_sub(&self, other: Self) -> Self;
	fn sub_ref(self, other: &Self) -> Self;
	fn ref_sub_ref(&self, other: &Self) -> Self;
	
	fn neg(self) -> Self;
	fn ref_neg(&self) -> Self;
	
	fn zero() -> Self;
}

struct Group<T: GenGroup>(pub T);

impl<T: GenGroup> Add<Group<T>> for Group<T> {
	type Output = Group<T>;
	
	fn add(self, rhs: Self) -> Group<T> {
		Group(self.0.add(rhs.0))
	}
}

impl<T: GenGroup> Add<&Group<T>> for Group<T> {
	type Output = Group<T>;
	
	fn add(self, rhs: &Self) -> Self {
		Group(self.0.add_ref(&rhs.0))
	}
}

%*$\dots$*)
\end{lstlisting}
\item \textbf{Custom Control-Flow / Dependency Inversion Principle}\\
Die Idee habe ich letztendlich nicht mehr ausgearbeitet, aber ich will sie trotzdem ansprechen. Im Grunde ist der Gedanke die Darstellung der Daten von der Logik zu trennen. Das kann man bspw. mit einem Execution-Graph erreichen. Konkret würde man die Daten, dann einer Kollektion als Wert hinzufügen und einen ``leichten'' Schlüsselwert für Rechnungen nutzen. Für diesen Schlüsselwert implementiert man Addition und so weiter. Das Endergebnis der Rechnung könnte man dann ``ausführen'' wobei die Kollektion übergeben wird. Die Idee ist nicht uninteressant und ermöglicht bspw. symbolische Berechnungen, aber verkompliziert nur alles, da man mehr Abstraktion und Komplexität hinzufügt.
\item \textbf{Macros}\\
Eine Reihe von Rust-Veteranen empfehlen bei solchen Problemen gerne die extensive Nutzung von Makros. An sich ist das eine legitime Option, aber mein Wissen über Makros ist auf der einen Hand eher oberflächlich, und auf der anderen Hand ist das Debuggen von Meta-Code immer nervig und anstrengend. Auch bin ich einfach kein Fan von ``Makro''-Libraries. Makros sind meiner Meinung nach eher dazu dar um Boilerplate-Code zu verstecken und nicht um Software zu designen.
\item \textbf{If it works, it works}\\
\textit{``Bro, du machst dir da zu viele Gedanken. Hier, mach das doch einfach mit den Referenzen. Das kompiliert doch. Das passt schon. Ist doch OK. Man kann doch hinterher immer noch mal eben eine bessere Version schreiben. Erstmal mit dem Einfachen anfangen. Du machst dir das alles zu schwer. Bill Gates sagte mal er stellt lieber faule Programmierer ein, weil [\dots]''}\\
\textbf{Nein!}
\end{itemize}
Anhand der Erklärung wird klar, dass ich ``Constrained Newtypes'' für die sinnvollste Lösung halte.

\subsection{Newtype Inheritance Wrapper or Copyable}
\subsubsection{Übersicht}
In diesem Abschnitt will ich das Pattern präzise definieren, das ich im Tensors-Crate verwende. Dazu definiere ich eine Reihe von Regeln an die ich mich halten will. Einige sind in direkter oder abgewandelter Form aus Rust's Repository für Design Patterns\footnote{\href{https://rust-unofficial.github.io/patterns}{rust-unofficial.github.io/patterns}} übernommen. Andere habe ich speziell für dieses Crate entworfen. Wie bereits oben diskutiert sind aus rein technischer Sicht bloße Traits und entsprechende Supertraits bereits das ``richtige Pattern''. Die Abstraktion über Newtypes wird in erster Linie für den syntaktischen Zucker verwendet ohne auf Makros zurückgreifen zu müssen.
%\subsubsection*{Durchgesetzte Patterns}
\begin{enumerate}[1)]
\item \textbf{Wrap via Newtypes if not \texttt{Copy}}\\
Angelehnt an \href{https://rust-unofficial.github.io/patterns/patterns/behavioural/newtype.html}{Newtype}. Falls der Trait \texttt{Copy} fordert, siehe \ref{Copy}. Andernfalls wird für den Trait \lstinline[language=Rust, morekeywords={GenX}]|GenX| der Wrapper \lstinline[language=Rust, morekeywords={GenX, X, T}]|struct X<T: GenX>(pub T)| definiert.
\item \textbf{Wrapper sind Smartpointer}\\
Übernommen von \href{https://rust-unofficial.github.io/patterns/idioms/deref.html}{Collections are smart pointers}. Alle Wrapper im Crate dienen vor allem dem Zweck die Abstraktionen der Traits über konkrete Datentypen darzustellen. Von daher implementieren sie alle den \texttt{Deref}-Trait.
\item \textbf{Dependency Inversion Principle}\\
Angelehnt an \href{https://rust-unofficial.github.io/patterns/patterns/behavioural/strategy.html}{Strategy}. Im Grunde ist dieses Pattern die eigentliche Daseins-Berechtigung dieses Crates. Es ermöglicht das Schreiben von Code für gewisse mathematische Objekte, ohne von einer konkreten Implementierung/Darstellung ausgehen zu müssen. Allerdings wird das Pattern nicht so stark wie im Punkt ``Custom Control-Flow'' angesprochen. Andersherum spricht aber nichts dagegen einen solchen custom Control-Flow ab Basis dieses Crates zu implementieren.
\item \textbf{Wrapper sind immer eine Ebene dünn}\\
Betrachte %\newpage
\begin{lstlisting}[language=Rust, numbers=left, emph={wrapped_group_impl!}, morekeywords={R, ops}]
trait GenGroup: Add<Self, Output = Self> + %*$\dots$*) {
	fn ref_add(&self, other: Self) -> Self;
	fn add_ref(self, other: &Self) -> Self;
	fn ref_add_ref(&self, other: &Self) -> Self;
	// %*$\dots$*)
}

trait GenVectorSpace: GenGroup + %*$\dots$*) {
	// %*$\dots$*)
}

macro_rules! wrapped_group_impl {
	($gen:tt, $w:tt) => (
		impl<T: $gen> std::ops::Add<$w<T>> for $w<T> {/*%*$\cdots$*)*/}

		impl<T: $gen, R: AsRef<$w<T>>> std::ops::Add<R> for $w<T> {/*%*$\cdots$*)*/}

		/* %*$\cdots$*) */
	)
}

struct Group<T: GenGroup>(pub T);
struct VectorSpace<T: GenVectorSpace>(pub T);

wrapped_group_impl!(GenGroup, Group); %*$\label{code:wrap_group_impl:1}$*)
wrapped_group_impl!(GenVectorSpace, VectorSpace); %*$\label{code:wrap_group_impl:2}$*)
\end{lstlisting}
Wichtig sind die letzten beiden Zeilen. Zeile \ref{code:wrap_group_impl:1} implementiert den eigentliche Wrapper für \texttt{Group}. Allerdings muss dieser Wrapper wie in Zeile \ref{code:wrap_group_impl:2} auch für \texttt{VectorSpace} implementiert werden. Das ermöglicht insbesondere, dass ein Typ \texttt{X}, der \texttt{GenVectorSpace} implementiert und in \texttt{VectorSpace} gewrappt wird, nicht neu in \texttt{Group} gewrappt werden muss um die Gruppenaddition nutzen zu können.
\item\label{Copy} \textbf{\texttt{Copy} $\Rightarrow$ Billig}\\
Für copyable Types wird auf das Newtype-Pattern verzichtet, weil ich davon ausgehe, dass Copies bereits extrem billig sind und der Compiler beim Optimieren den unnützen Overhead fast restlos entfernen kann.
\end{enumerate}

\include{tensor-crate-docs-appendix}

\end{document}

